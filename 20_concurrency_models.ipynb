{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 20. Concurrency Models in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit of jargon\n",
    "\n",
    "**concurrency**: The ability to handle multiple pending tasks, making progress one at a time or in parallel (not necessarily) so that they all eventually succeed or fail. A single-core CPU is capable of concurrency if it turns an OS scheduler that interleaves the execution of the pending tasks. Also known as multitasking.\n",
    "\n",
    "**parallelism**: The ability to execute multiple computations at the same time. This requires a multi-core CPU, a GPU, or multiple computers in cluster.\n",
    "\n",
    "**process**: An instance of a computer program while it is running, using memory and a slice of the CPU time. Modern operating systems are able to manage multiple process concurrently, with each process isolated in its own private memory space. Processes communicate via pipes, sockets or memory mapped files -- all of which can only carry raw bytes, not live Python objects. A process can spawn sub-processes, each called a child process. These are also isolated from each other an from the parent.\n",
    "\n",
    "**thread**: An execution path within a single process. When a process starts, it uses a single thread: the main thread. Using operating systems APIs, a process can create more threads that operate concurrently thanks to operating system scheduler. Threads share the memory space of the process, which holds live Python objects. This allows easy communication between threads, but can also lead to corrupted data when more than one thread updates the same object concurrently.\n",
    "\n",
    "**contention**: Dispute over a limited asset. Resource contention happens when multiple processes or threads try to access a shared resource -- such as lock or storage. There is also CPU contention, when compute-intensive processes or threads must wait for their share of CPU time.\n",
    "\n",
    "**lock**: An object that threads can use to coordinate and synchronize their actions and avoid corrupting data. While updating a shared data structure, a thread should hold an associated lock. This makes other well-behaved threads wait until the lock is released before accessing the same data structure. This simplest type of lock is also known as a mutex (for mutual exclusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A concurrent hello world\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "def spin(msg, done):\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, end='', flush=True)\n",
    "        if done.wait(.5):\n",
    "            break\n",
    "    blanks = ' ' * len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "\n",
    "def slow():\n",
    "    time.sleep(3)\n",
    "    return 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spiner object: <Thread(Thread-5 (spin), initial)>\n",
      "Answer: 42 \n"
     ]
    }
   ],
   "source": [
    "# Supervisor and main functions\n",
    "from threading import Thread, Event\n",
    "\n",
    "def supervisor():\n",
    "    done = Event()\n",
    "    spinner = Thread(target=spin, args=('thinking', done))\n",
    "    print(f'spiner object: {spinner}')\n",
    "\n",
    "    spinner.start()\n",
    "    result = slow()\n",
    "    done.set()\n",
    "    spinner.join()\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    result = supervisor()\n",
    "    print(f'Answer: {result}')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spinner with multiprocessing\n",
    "\n",
    "The multiprocessing package supports running concurrent tasks in separate Python processes instead of threads. When you create a `multiprocessing.Process` instance, a whole new Python interpreter is started as a child process in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spinner object: <Process name='Process-1' parent=70264 initial>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'spin' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 42\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Event\n",
    "from multiprocessing import synchronize\n",
    "\n",
    "def process_supervisor():\n",
    "    done = Event()\n",
    "    spinner = Process(target=spin, args=('thinking!', done))\n",
    "    print(f'spinner object: {spinner}')\n",
    "\n",
    "    spinner.start()\n",
    "    result = slow()\n",
    "    done.set()\n",
    "    spinner.join()\n",
    "    return result\n",
    "\n",
    "def process_main():\n",
    "    result = process_supervisor()\n",
    "    print(f'Answer: {result}')\n",
    "\n",
    "process_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spinner with asyncio\n",
    "\n",
    "It is the job of OS schedulers to allocate CPI time to drive threads and processes. In contrast, coroutines are driven by an application-level event loop that manages a queue of pending coroutines, drives them one by one, monitors events triggered by I/O operations initiated by coroutines, and passes control back to the corresponding coroutine when each event happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coroutine version of the spinner program\n",
    "import asyncio\n",
    "\n",
    "async def spin(msg):\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, flush=True, end='')\n",
    "        try:\n",
    "            await asyncio.sleep(.1)\n",
    "        except asyncio.CancelledError:\n",
    "            break\n",
    "    blanks = ' ' * len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "    \n",
    "async def slow():\n",
    "    await asyncio.sleep(3)\n",
    "    return 42\n",
    "\n",
    "async def supervisor():\n",
    "    spinner = asyncio.create_task(spin('thinking!'))\n",
    "    print(f'spinner object: {spinner}')\n",
    "    result = await slow()\n",
    "    spinner.cancel()\n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    result = asyncio.run(supervisor())\n",
    "    print(f'Answer: {result}')                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example above demonstrates the three main ways of running a coroutine:\n",
    "\n",
    "`asyncio.run(coro())`\\\n",
    "Called from a regular function to drive a coroutine object which usually is the entry point for all the asynchronous code in the program, like the supervisor in this example. This call blocks until the body of `coro` returns. The return value of the `run()` calls is whatever the body of `coro` returns.\n",
    "\n",
    "`asyncio.create_task(coro())`\\\n",
    "Called from a coroutine to schedule another coroutine to execute eventually. This call does not suspend the current coroutine. It returns a `Task` instance, an object that wraps the coroutine object and provides methods to control and query its state.\n",
    "\n",
    "`await coro()`\n",
    "Called from a coroutine to transfer control to the coroutine object returned by `coro()`. This suspends the current coroutine until the body of `coro` returns. The value of the await expression is whatever the body of `coro` returns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Real impact of the GIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04 s ± 12.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True \n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "        \n",
    "    root = math.isqrt(n)\n",
    "    for i in range(3, root + 1, 2):\n",
    "        if n % i == 0: \n",
    "            return False\n",
    "    return True\n",
    "\n",
    "%timeit is_prime(5_000_111_000_222_021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Baseline for comparing sequential, multiprocessing and threading code for CPU-intensive work\n",
    "\"\"\"\n",
    "\n",
    "from time import perf_counter\n",
    "from typing import NamedTuple\n",
    "\n",
    "NUMBERS = (3333333333333333,9999999999999917)\n",
    "\n",
    "class Result(NamedTuple):\n",
    "    prime: bool\n",
    "    elapsed: float\n",
    "\n",
    "def check(n):\n",
    "    t0 = perf_counter()\n",
    "    prime = is_prime(n)\n",
    "    return Result(prime, perf_counter() - t0)\n",
    "\n",
    "def main():\n",
    "    print(f'Checkin {len(NUMBERS)} numbers sequentially')\n",
    "    t0 = perf_counter()\n",
    "    for n in NUMBERS:\n",
    "        prime, elapsed = check(n)\n",
    "        label = 'P' if prime else ' '\n",
    "        print(f'{n:16} {label} {elapsed:9.6f}s')\n",
    "    elpased = perf_counter() - t0\n",
    "    print(f'Total time {elapsed:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkin 2 numbers sequentially\n",
      "3333333333333333    0.000010s\n",
      "9999999999999917 P  1.507942s\n",
      "Total time 1.51s\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multiprocess primality check; imports, types and functions\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from time import perf_counter\n",
    "from typing import NamedTuple\n",
    "from multiprocessing import Process, SimpleQueue, cpu_count\n",
    "from multiprocessing import queues\n",
    "\n",
    "NUMBERS = (3333333333333333,9999999999999917)\n",
    "\n",
    "class PrimeResult(NamedTuple):\n",
    "    n: int\n",
    "    prime: bool\n",
    "    elapsed: float\n",
    "\n",
    "JobQueue = queues.SimpleQueue[int]\n",
    "ResultQueue = queues.SimpleQueue[PrimeResult]\n",
    "\n",
    "def check(n):\n",
    "    t0 = perf_counter()\n",
    "    res = is_prime(n)\n",
    "    return PrimeResult(n, res, perf_counter() - t0)\n",
    "\n",
    "def worker(jobs, results):\n",
    "    while n:= jobs.get():\n",
    "        results.put(check(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    workers = cpu_count()\n",
    "    print(f'Checking {len(NUMBERS)} numbers with {workers} processes:')\n",
    "\n",
    "    jobs = SimpleQueue()\n",
    "    results = SimpleQueue()\n",
    "    t0 = perf_counter()\n",
    "\n",
    "    for n in NUMBERS:\n",
    "        jobs.put(n)\n",
    "\n",
    "    for _ in range(workers):\n",
    "        proc = Process(target=worker, args=(jobs, results))\n",
    "        proc.start()\n",
    "        jobs.put(0)\n",
    "\n",
    "    while True:\n",
    "        n, prime, elapsed = results.get()\n",
    "        label = 'P' if prime else ' '\n",
    "        print(f'{n:16} {label} {elapsed:9.6f}s') \n",
    "        \n",
    "        if jobs.empty():\n",
    "            break\n",
    "\n",
    "    elapsed = perf_counter() - t0 \n",
    "    print(f'Total time: {elapsed:.2f}s')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter Summary\n",
    "\n",
    "After a bit of theory, this chapter presented the spinner scripts implemented in each of Python's three native concurrency programming models:\n",
    "- Threads, using `threading` package;\n",
    "- Processes, using `multiprocessing`;\n",
    "- Asynchronous coroutines with `asyncio`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then explored the real impact of the GIL with an experiment: changing the spinner examples to compute the primality of a large integer and observe the resulting behavior.\n",
    "\n",
    "- This demonstrated graphically that CPU- intensive functions must be avoided in asyncio, as they block the event loop;\n",
    "- The threaded version of the experiment worked—despite the GIL— because Python periodically interrupts threads, and the example used only two threads;\n",
    "- The multiprocessing variant worked around the GIL, starting a new process just for the animation while the main process did the primality check.\n",
    "\n",
    "The next example, computing several primes, highlighted the difference between multiprocessing and threading, proving that only processes allow Python to benefit from multicore CPUs. Python’s GIL makes threads worse than sequential code for heavy computations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
